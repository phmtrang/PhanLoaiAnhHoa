# -*- coding: utf-8 -*-
"""TestFlowersClassification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uFmlAzBtU3WuKTdj2hqHGaofsWECi-61
"""

from google.colab import drive
drive.mount('/content/drive')

# Thêm thư viện
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import classification_report,confusion_matrix
from imutils import paths
from keras.applications.vgg16 import VGG16
from keras.applications import imagenet_utils
from keras.preprocessing.image import img_to_array
from keras.preprocessing.image import load_img
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import LabelBinarizer
from sklearn.model_selection import train_test_split
import numpy as np
import random
import os
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.svm import SVC
import joblib
import cv2
from sklearn.utils.extmath import softmax
from keras import models
from keras import layers
from keras import optimizers
import tensorflow as tf
from tensorflow import keras

!unzip /content/drive/MyDrive/Test/Test.zip

# Lấy các đường dẫn đến ảnh.
image_path_test = list(paths.list_images('Test/'))
print(image_path_test)

model = VGG16(weights='imagenet', include_top=False)

# Đường dẫn ảnh sẽ là dataset/tên_loài_hoa/tên_ảnh ví dụ dataset/Bluebell/image_0241.jpg nên p.split(os.path.sep)[-2] sẽ lấy ra được tên loài hoa
labels_test = [p.split(os.path.sep)[-2] for p in image_path_test]

# Chuyển tên các loài hoa thành số
le = LabelEncoder()
labels_test = le.fit_transform(labels_test)

lb = LabelBinarizer()
labels_test= lb.fit_transform(labels_test)

list_image_test = []
for (j, imagePath) in enumerate(image_path_test):
    image_test = load_img(imagePath, target_size=(224, 224))
    image_test = img_to_array(image_test)
    
    image_test = np.expand_dims(image_test, 0)
    
    image_test = imagenet_utils.preprocess_input(image_test)
    
    list_image_test.append(image_test)
    
list_image_test = np.vstack(list_image_test)

features_test = model.predict(list_image_test)

# Giống bước flatten trong CNN, chuyển từ tensor 3 chiều sau ConvNet sang vector 1 chiều
features_test = features_test.reshape((features_test.shape[0], 512*7*7))

X_test= features_test
y_test = labels_test

new_model = tf.keras.models.load_model('/content/my_model1.h5')

new_model.summary()

y_pred = new_model.predict(X_test,verbose=0)
rounded_labels=np.argmax(y_test, axis=1)
rounded_pred=np.argmax(y_pred, axis=1)
print(confusion_matrix(rounded_labels,rounded_pred))
print(classification_report(rounded_labels,rounded_pred))

results={
   0:'astilbe',
   1:'bellflower',
   2:'black-eyed susan',
   3:'calendula',
   4:'california_poppy',
   5:'tulip'
}
pred=new_model.predict(features_test)
predict_label = []
for item in pred:
  predict_label.append(results[np.argmax(item)])
print(predict_label)

sort_pre_lable =   sorted(predict_label)
print(sort_pre_lable)